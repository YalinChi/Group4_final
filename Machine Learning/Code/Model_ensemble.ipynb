{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import datetime\n",
    "import copy\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import plotly.express as px\n",
    "import pyarrow as pa\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "import joblib\n",
    "import catboost as cb\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "import holidays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataStorage:\n",
    "    root = \"..\\data\"\n",
    "    # root = \"/content/drive/MyDrive/predict-energy-behavior-of-prosumers/Data\"\n",
    "    # root = \"/kaggle/input/predict-energy-behavior-of-prosumers\"\n",
    "\n",
    "    data_cols = [\n",
    "        \"target\",\n",
    "        \"county\",\n",
    "        \"is_business\",\n",
    "        \"product_type\",\n",
    "        \"is_consumption\",\n",
    "        \"datetime\",\n",
    "        \"row_id\",\n",
    "    ]\n",
    "    client_cols = [\n",
    "        \"product_type\",\n",
    "        \"county\",\n",
    "        \"eic_count\",\n",
    "        \"installed_capacity\",\n",
    "        \"is_business\",\n",
    "        \"date\",\n",
    "    ]\n",
    "    gas_prices_cols = [\"forecast_date\", \"lowest_price_per_mwh\", \"highest_price_per_mwh\"]\n",
    "    electricity_prices_cols = [\"forecast_date\", \"euros_per_mwh\"]\n",
    "    forecast_weather_cols = [\n",
    "        \"latitude\",\n",
    "        \"longitude\",\n",
    "        \"origin_datetime\",\n",
    "        \"hours_ahead\",\n",
    "        \"temperature\",\n",
    "        \"dewpoint\",\n",
    "        \"cloudcover_high\",\n",
    "        \"cloudcover_low\",\n",
    "        \"cloudcover_mid\",\n",
    "        \"cloudcover_total\",\n",
    "        \"10_metre_u_wind_component\",\n",
    "        \"10_metre_v_wind_component\",\n",
    "        \"forecast_datetime\",\n",
    "        \"direct_solar_radiation\",\n",
    "        \"surface_solar_radiation_downwards\",\n",
    "        \"snowfall\",\n",
    "        \"total_precipitation\",\n",
    "    ]\n",
    "    historical_weather_cols = [\n",
    "        \"datetime\",\n",
    "        \"temperature\",\n",
    "        \"dewpoint\",\n",
    "        \"rain\",\n",
    "        \"snowfall\",\n",
    "        \"surface_pressure\",\n",
    "        \"cloudcover_total\",\n",
    "        \"cloudcover_low\",\n",
    "        \"cloudcover_mid\",\n",
    "        \"cloudcover_high\",\n",
    "        \"windspeed_10m\",\n",
    "        \"winddirection_10m\",\n",
    "        \"shortwave_radiation\",\n",
    "        \"direct_solar_radiation\",\n",
    "        \"diffuse_radiation\",\n",
    "        \"latitude\",\n",
    "        \"longitude\",\n",
    "    ]\n",
    "    location_cols = [\"longitude\", \"latitude\", \"county\"]\n",
    "    target_cols = [\n",
    "        \"target\",\n",
    "        \"county\",\n",
    "        \"is_business\",\n",
    "        \"product_type\",\n",
    "        \"is_consumption\",\n",
    "        \"datetime\",\n",
    "    ]\n",
    "\n",
    "    def __init__(self):\n",
    "        self.df_data = pl.read_csv(\n",
    "            os.path.join(self.root, \"train.csv\"),\n",
    "            columns=self.data_cols,\n",
    "            try_parse_dates=True,\n",
    "        )\n",
    "        self.df_client = pl.read_csv(\n",
    "            os.path.join(self.root, \"client.csv\"),\n",
    "            columns=self.client_cols,\n",
    "            try_parse_dates=True,\n",
    "        )\n",
    "        self.df_gas_prices = pl.read_csv(\n",
    "            os.path.join(self.root, \"gas_prices.csv\"),\n",
    "            columns=self.gas_prices_cols,\n",
    "            try_parse_dates=True,\n",
    "        )\n",
    "        self.df_electricity_prices = pl.read_csv(\n",
    "            os.path.join(self.root, \"electricity_prices.csv\"),\n",
    "            columns=self.electricity_prices_cols,\n",
    "            try_parse_dates=True,\n",
    "        )\n",
    "        self.df_forecast_weather = pl.read_csv(\n",
    "            os.path.join(self.root, \"forecast_weather.csv\"),\n",
    "            columns=self.forecast_weather_cols,\n",
    "            try_parse_dates=True,\n",
    "        )\n",
    "        self.df_historical_weather = pl.read_csv(\n",
    "            os.path.join(self.root, \"historical_weather.csv\"),\n",
    "            columns=self.historical_weather_cols,\n",
    "            try_parse_dates=True,\n",
    "        )\n",
    "        self.df_weather_station_to_county_mapping = pl.read_csv(\n",
    "            os.path.join(self.root, \"weather_station_to_county_mapping.csv\"),\n",
    "            columns=self.location_cols,\n",
    "            try_parse_dates=True,\n",
    "        )\n",
    "        self.df_data = self.df_data.filter(\n",
    "            pl.col(\"datetime\") >= pd.to_datetime(\"2022-01-01\")\n",
    "        )\n",
    "        self.df_target = self.df_data.select(self.target_cols)\n",
    "\n",
    "        self.schema_data = self.df_data.schema\n",
    "        self.schema_client = self.df_client.schema\n",
    "        self.schema_gas_prices = self.df_gas_prices.schema\n",
    "        self.schema_electricity_prices = self.df_electricity_prices.schema\n",
    "        self.schema_forecast_weather = self.df_forecast_weather.schema\n",
    "        self.schema_historical_weather = self.df_historical_weather.schema\n",
    "        self.schema_target = self.df_target.schema\n",
    "\n",
    "        self.df_weather_station_to_county_mapping = (\n",
    "            self.df_weather_station_to_county_mapping.with_columns(\n",
    "                pl.col(\"latitude\").cast(pl.datatypes.Float32),\n",
    "                pl.col(\"longitude\").cast(pl.datatypes.Float32),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def update_with_new_data(\n",
    "        self,\n",
    "        df_new_client,\n",
    "        df_new_gas_prices,\n",
    "        df_new_electricity_prices,\n",
    "        df_new_forecast_weather,\n",
    "        df_new_historical_weather,\n",
    "        df_new_target,\n",
    "    ):\n",
    "        df_new_client = pl.from_pandas(\n",
    "            df_new_client[self.client_cols], schema_overrides=self.schema_client\n",
    "        )\n",
    "        df_new_gas_prices = pl.from_pandas(\n",
    "            df_new_gas_prices[self.gas_prices_cols],\n",
    "            schema_overrides=self.schema_gas_prices,\n",
    "        )\n",
    "        df_new_electricity_prices = pl.from_pandas(\n",
    "            df_new_electricity_prices[self.electricity_prices_cols],\n",
    "            schema_overrides=self.schema_electricity_prices,\n",
    "        )\n",
    "        df_new_forecast_weather = pl.from_pandas(\n",
    "            df_new_forecast_weather[self.forecast_weather_cols],\n",
    "            schema_overrides=self.schema_forecast_weather,\n",
    "        )\n",
    "        df_new_historical_weather = pl.from_pandas(\n",
    "            df_new_historical_weather[self.historical_weather_cols],\n",
    "            schema_overrides=self.schema_historical_weather,\n",
    "        )\n",
    "        df_new_target = pl.from_pandas(\n",
    "            df_new_target[self.target_cols], schema_overrides=self.schema_target\n",
    "        )\n",
    "\n",
    "        self.df_client = pl.concat([self.df_client, df_new_client]).unique(\n",
    "            [\"date\", \"county\", \"is_business\", \"product_type\"]\n",
    "        )\n",
    "        self.df_gas_prices = pl.concat([self.df_gas_prices, df_new_gas_prices]).unique(\n",
    "            [\"forecast_date\"]\n",
    "        )\n",
    "        self.df_electricity_prices = pl.concat(\n",
    "            [self.df_electricity_prices, df_new_electricity_prices]\n",
    "        ).unique([\"forecast_date\"])\n",
    "        self.df_forecast_weather = pl.concat(\n",
    "            [self.df_forecast_weather, df_new_forecast_weather]\n",
    "        ).unique([\"forecast_datetime\", \"latitude\", \"longitude\", \"hours_ahead\"])\n",
    "        self.df_historical_weather = pl.concat(\n",
    "            [self.df_historical_weather, df_new_historical_weather]\n",
    "        ).unique([\"datetime\", \"latitude\", \"longitude\"])\n",
    "        self.df_target = pl.concat([self.df_target, df_new_target]).unique(\n",
    "            [\"datetime\", \"county\", \"is_business\", \"product_type\", \"is_consumption\"]\n",
    "        )\n",
    "\n",
    "    def preprocess_test(self, df_test):\n",
    "        df_test = df_test.rename(columns={\"prediction_datetime\": \"datetime\"})\n",
    "        df_test = pl.from_pandas(\n",
    "            df_test[self.data_cols[1:]], schema_overrides=self.schema_data\n",
    "        )\n",
    "        return df_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Enegineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturesGenerator:\n",
    "    def __init__(self, data_storage):\n",
    "        self.data_storage = data_storage\n",
    "        self.estonian_holidays = list(\n",
    "            holidays.country_holidays(\"EE\", years=range(2021, 2026)).keys()\n",
    "        )\n",
    "\n",
    "    def _add_general_features(self, df_features):\n",
    "        df_features = (\n",
    "            df_features.with_columns(\n",
    "                pl.col(\"datetime\").dt.ordinal_day().alias(\"dayofyear\"),\n",
    "                pl.col(\"datetime\").dt.hour().alias(\"hour\"),\n",
    "                pl.col(\"datetime\").dt.day().alias(\"day\"),\n",
    "                pl.col(\"datetime\").dt.weekday().alias(\"weekday\"),\n",
    "                pl.col(\"datetime\").dt.month().alias(\"month\"),\n",
    "                pl.col(\"datetime\").dt.year().alias(\"year\"),\n",
    "            )\n",
    "            .with_columns(\n",
    "                pl.concat_str(\n",
    "                    \"county\",\n",
    "                    \"is_business\",\n",
    "                    \"product_type\",\n",
    "                    \"is_consumption\",\n",
    "                    separator=\"_\",\n",
    "                ).alias(\"segment\"),\n",
    "            )\n",
    "            .with_columns(\n",
    "                (np.pi * pl.col(\"dayofyear\") / 183).sin().alias(\"sin(dayofyear)\"),\n",
    "                (np.pi * pl.col(\"dayofyear\") / 183).cos().alias(\"cos(dayofyear)\"),\n",
    "                (np.pi * pl.col(\"hour\") / 12).sin().alias(\"sin(hour)\"),\n",
    "                (np.pi * pl.col(\"hour\") / 12).cos().alias(\"cos(hour)\"),\n",
    "            )\n",
    "        )\n",
    "        return df_features\n",
    "\n",
    "    def _add_client_features(self, df_features):\n",
    "        df_client = self.data_storage.df_client\n",
    "\n",
    "        df_features = df_features.join(\n",
    "            df_client.with_columns(\n",
    "                (pl.col(\"date\") + pl.duration(days=2)).cast(pl.Date)\n",
    "            ),\n",
    "            on=[\"county\", \"is_business\", \"product_type\", \"date\"],\n",
    "            how=\"left\",\n",
    "        )\n",
    "        return df_features\n",
    "    \n",
    "    def is_country_holiday(self, row):\n",
    "        return (\n",
    "            datetime.date(row[\"year\"], row[\"month\"], row[\"day\"])\n",
    "            in self.estonian_holidays\n",
    "        )\n",
    "\n",
    "    def _add_holidays_features(self, df_features):\n",
    "        df_features = df_features.with_columns(\n",
    "            pl.struct([\"year\", \"month\", \"day\"])\n",
    "            .apply(self.is_country_holiday)\n",
    "            .alias(\"is_country_holiday\")\n",
    "        )\n",
    "        return df_features\n",
    "\n",
    "    def _add_forecast_weather_features(self, df_features):\n",
    "        df_forecast_weather = self.data_storage.df_forecast_weather\n",
    "        df_weather_station_to_county_mapping = (\n",
    "            self.data_storage.df_weather_station_to_county_mapping\n",
    "        )\n",
    "\n",
    "        df_forecast_weather = (\n",
    "            df_forecast_weather.rename({\"forecast_datetime\": \"datetime\"})\n",
    "            .filter((pl.col(\"hours_ahead\") >= 22) & pl.col(\"hours_ahead\") <= 45)\n",
    "            .drop(\"hours_ahead\")\n",
    "            .with_columns(\n",
    "                pl.col(\"latitude\").cast(pl.datatypes.Float32),\n",
    "                pl.col(\"longitude\").cast(pl.datatypes.Float32),\n",
    "            )\n",
    "            .join(\n",
    "                df_weather_station_to_county_mapping,\n",
    "                how=\"left\",\n",
    "                on=[\"longitude\", \"latitude\"],\n",
    "            )\n",
    "            .drop(\"longitude\", \"latitude\", \"origin_datetime\")\n",
    "        )\n",
    "\n",
    "        df_forecast_weather_date = (\n",
    "            df_forecast_weather.group_by(\"datetime\").mean().drop(\"county\")\n",
    "        )\n",
    "\n",
    "        df_forecast_weather_local = (\n",
    "            df_forecast_weather.filter(pl.col(\"county\").is_not_null())\n",
    "            .group_by(\"county\", \"datetime\")\n",
    "            .mean()\n",
    "        )\n",
    "\n",
    "        for hours_lag in [0, 7 * 24]:\n",
    "            df_features = df_features.join(\n",
    "                df_forecast_weather_date.with_columns(\n",
    "                    pl.col(\"datetime\") + pl.duration(hours=hours_lag)\n",
    "                ),\n",
    "                on=\"datetime\",\n",
    "                how=\"left\",\n",
    "                suffix=f\"_forecast_{hours_lag}h\",\n",
    "            )\n",
    "            df_features = df_features.join(\n",
    "                df_forecast_weather_local.with_columns(\n",
    "                    pl.col(\"datetime\") + pl.duration(hours=hours_lag)\n",
    "                ),\n",
    "                on=[\"county\", \"datetime\"],\n",
    "                how=\"left\",\n",
    "                suffix=f\"_forecast_local_{hours_lag}h\",\n",
    "            )\n",
    "            \n",
    "        df_features = df_features.with_columns(\n",
    "            (\n",
    "                pl.col(f\"temperature_forecast_local_0h\")\n",
    "                / (pl.col(f\"temperature_forecast_local_168h\") + 1e-3)\n",
    "            ).alias(f\"temperature_forecast_local_0h/168h\"),\n",
    "            (\n",
    "                pl.col(f\"surface_solar_radiation_downwards_forecast_local_0h\")\n",
    "                / (pl.col(f\"surface_solar_radiation_downwards_forecast_local_168h\") + 1e-3)\n",
    "            ).alias(f\"surface_solar_radiation_downwards_forecast_local_0h/168h\"),\n",
    "        )\n",
    "\n",
    "        return df_features\n",
    "\n",
    "    def _add_historical_weather_features(self, df_features):\n",
    "        df_historical_weather = self.data_storage.df_historical_weather\n",
    "        df_weather_station_to_county_mapping = (\n",
    "            self.data_storage.df_weather_station_to_county_mapping\n",
    "        )\n",
    "\n",
    "        df_historical_weather = (\n",
    "            df_historical_weather.with_columns(\n",
    "                pl.col(\"latitude\").cast(pl.datatypes.Float32),\n",
    "                pl.col(\"longitude\").cast(pl.datatypes.Float32),\n",
    "            )\n",
    "            .join(\n",
    "                df_weather_station_to_county_mapping,\n",
    "                how=\"left\",\n",
    "                on=[\"longitude\", \"latitude\"],\n",
    "            )\n",
    "            .drop(\"longitude\", \"latitude\")\n",
    "        )\n",
    "\n",
    "        df_historical_weather_date = (\n",
    "            df_historical_weather.group_by(\"datetime\").mean().drop(\"county\")\n",
    "        )\n",
    "\n",
    "        df_historical_weather_local = (\n",
    "            df_historical_weather.filter(pl.col(\"county\").is_not_null())\n",
    "            .group_by(\"county\", \"datetime\")\n",
    "            .mean()\n",
    "        )\n",
    "\n",
    "        for hours_lag in [2 * 24, 7 * 24]:\n",
    "            df_features = df_features.join(\n",
    "                df_historical_weather_date.with_columns(\n",
    "                    pl.col(\"datetime\") + pl.duration(hours=hours_lag)\n",
    "                ),\n",
    "                on=\"datetime\",\n",
    "                how=\"left\",\n",
    "                suffix=f\"_historical_{hours_lag}h\",\n",
    "            )\n",
    "            df_features = df_features.join(\n",
    "                df_historical_weather_local.with_columns(\n",
    "                    pl.col(\"datetime\") + pl.duration(hours=hours_lag)\n",
    "                ),\n",
    "                on=[\"county\", \"datetime\"],\n",
    "                how=\"left\",\n",
    "                suffix=f\"_historical_local_{hours_lag}h\",\n",
    "            )\n",
    "\n",
    "        for hours_lag in [1 * 24]:\n",
    "            df_features = df_features.join(\n",
    "                df_historical_weather_date.with_columns(\n",
    "                    pl.col(\"datetime\") + pl.duration(hours=hours_lag),\n",
    "                    pl.col(\"datetime\").dt.hour().alias(\"hour\"),\n",
    "                )\n",
    "                .filter(pl.col(\"hour\") <= 10)\n",
    "                .drop(\"hour\"),\n",
    "                on=\"datetime\",\n",
    "                how=\"left\",\n",
    "                suffix=f\"_historical_{hours_lag}h\",\n",
    "            )\n",
    "            \n",
    "        df_features = df_features.with_columns(\n",
    "            (\n",
    "                pl.col(f\"temperature_historical_local_48h\")\n",
    "                / (pl.col(f\"temperature_historical_local_168h\") + 1e-3)\n",
    "            ).alias(f\"temperature_historical_local_48h/168h\"),\n",
    "            (\n",
    "                pl.col(f\"direct_solar_radiation_historical_local_48h\")\n",
    "                / (pl.col(f\"direct_solar_radiation_historical_local_168h\") + 1e-3)\n",
    "            ).alias(f\"direct_solar_radiation_historical_local_48h/168h\"),\n",
    "            (\n",
    "                pl.col(f\"temperature_historical_24h\")\n",
    "                / (pl.col(f\"temperature\") + 1e-3)\n",
    "            ).alias(f\"temperature_historical_24h/48h\"),\n",
    "            (\n",
    "                pl.col(f\"direct_solar_radiation_historical_24h\")\n",
    "                / (pl.col(f\"direct_solar_radiation\") + 1e-3)\n",
    "            ).alias(f\"direct_solar_radiation_historical_24h/48h\"),\n",
    "        )\n",
    "\n",
    "        return df_features\n",
    "\n",
    "    def _add_target_features(self, df_features):\n",
    "        df_target = self.data_storage.df_target\n",
    "\n",
    "        df_target_all_type_sum = (\n",
    "            df_target.group_by([\"datetime\", \"county\", \"is_business\", \"is_consumption\"])\n",
    "            .sum()\n",
    "            .drop(\"product_type\")\n",
    "        )\n",
    "\n",
    "        df_target_all_county_type_sum = (\n",
    "            df_target.group_by([\"datetime\", \"is_business\", \"is_consumption\"])\n",
    "            .sum()\n",
    "            .drop(\"product_type\", \"county\")\n",
    "        )\n",
    "\n",
    "        for hours_lag in [\n",
    "            2 * 24,\n",
    "            3 * 24,\n",
    "            4 * 24,\n",
    "            5 * 24,\n",
    "            6 * 24,\n",
    "            7 * 24,\n",
    "            8 * 24,\n",
    "            9 * 24,\n",
    "            10 * 24,\n",
    "            11 * 24,\n",
    "            12 * 24,\n",
    "            13 * 24,\n",
    "            14 * 24,\n",
    "        ]:\n",
    "            df_features = df_features.join(\n",
    "                df_target.with_columns(\n",
    "                    pl.col(\"datetime\") + pl.duration(hours=hours_lag)\n",
    "                ).rename({\"target\": f\"target_{hours_lag}h\"}),\n",
    "                on=[\n",
    "                    \"county\",\n",
    "                    \"is_business\",\n",
    "                    \"product_type\",\n",
    "                    \"is_consumption\",\n",
    "                    \"datetime\",\n",
    "                ],\n",
    "                how=\"left\",\n",
    "            )\n",
    "\n",
    "        for hours_lag in [2 * 24, 3 * 24, 7 * 24, 14 * 24]:\n",
    "            df_features = df_features.join(\n",
    "                df_target_all_type_sum.with_columns(\n",
    "                    pl.col(\"datetime\") + pl.duration(hours=hours_lag)\n",
    "                ).rename({\"target\": f\"target_all_type_sum_{hours_lag}h\"}),\n",
    "                on=[\"county\", \"is_business\", \"is_consumption\", \"datetime\"],\n",
    "                how=\"left\",\n",
    "            )\n",
    "\n",
    "            df_features = df_features.join(\n",
    "                df_target_all_county_type_sum.with_columns(\n",
    "                    pl.col(\"datetime\") + pl.duration(hours=hours_lag)\n",
    "                ).rename({\"target\": f\"target_all_county_type_sum_{hours_lag}h\"}),\n",
    "                on=[\"is_business\", \"is_consumption\", \"datetime\"],\n",
    "                how=\"left\",\n",
    "                suffix=f\"_all_county_type_sum_{hours_lag}h\",\n",
    "            )\n",
    "\n",
    "        cols_for_stats = [\n",
    "            f\"target_{hours_lag}h\" for hours_lag in [2 * 24, 3 * 24, 4 * 24, 5 * 24]\n",
    "        ]\n",
    "        df_features = df_features.with_columns(\n",
    "            df_features.select(cols_for_stats).mean(axis=1).alias(f\"target_mean\"),\n",
    "            df_features.select(cols_for_stats)\n",
    "            .transpose()\n",
    "            .std()\n",
    "            .transpose()\n",
    "            .to_series()\n",
    "            .alias(f\"target_std\"),\n",
    "        )\n",
    "\n",
    "        for target_prefix, lag_nominator, lag_denomonator in [\n",
    "            (\"target\", 24 * 7, 24 * 14),\n",
    "            (\"target\", 24 * 2, 24 * 9),\n",
    "            (\"target\", 24 * 3, 24 * 10),\n",
    "            (\"target\", 24 * 2, 24 * 3),\n",
    "            (\"target_all_type_sum\", 24 * 2, 24 * 3),\n",
    "            (\"target_all_type_sum\", 24 * 7, 24 * 14),\n",
    "            (\"target_all_county_type_sum\", 24 * 2, 24 * 3),\n",
    "            (\"target_all_county_type_sum\", 24 * 7, 24 * 14),\n",
    "        ]:\n",
    "            df_features = df_features.with_columns(\n",
    "                (\n",
    "                    pl.col(f\"{target_prefix}_{lag_nominator}h\")\n",
    "                    / (pl.col(f\"{target_prefix}_{lag_denomonator}h\") + 1e-3)\n",
    "                ).alias(f\"{target_prefix}_ratio_{lag_nominator}_{lag_denomonator}\")\n",
    "            )\n",
    "\n",
    "        return df_features\n",
    "\n",
    "    def _reduce_memory_usage(self, df_features):\n",
    "        df_features = df_features.with_columns(pl.col(pl.Float64).cast(pl.Float32))\n",
    "        return df_features\n",
    "\n",
    "    def _drop_columns(self, df_features):\n",
    "        df_features = df_features.drop(\n",
    "            \"date\", \"datetime\", \"hour\", \"dayofyear\"\n",
    "        )\n",
    "        return df_features\n",
    "\n",
    "    def _to_pandas(self, df_features, y):\n",
    "        cat_cols = [\n",
    "            \"county\",\n",
    "            \"is_business\",\n",
    "            \"product_type\",\n",
    "            \"is_consumption\",\n",
    "            \"segment\",\n",
    "        ]\n",
    "\n",
    "        if y is not None:\n",
    "            df_features = pd.concat([df_features.to_pandas(), y.to_pandas()], axis=1)\n",
    "        else:\n",
    "            df_features = df_features.to_pandas()\n",
    "\n",
    "        df_features[cat_cols] = df_features[cat_cols].astype(\"category\")\n",
    "        \n",
    "        if 'row_id' in df_features.columns:\n",
    "            df_features = df_features.drop(\"row_id\", axis=1)\n",
    "\n",
    "        return df_features\n",
    "\n",
    "    def generate_features(self, df_prediction_items):\n",
    "        if \"target\" in df_prediction_items.columns:\n",
    "            df_prediction_items, y = (\n",
    "                df_prediction_items.drop(\"target\"),\n",
    "                df_prediction_items.select(\"target\"),\n",
    "            )\n",
    "        else:\n",
    "            y = None\n",
    "\n",
    "        df_features = df_prediction_items.with_columns(\n",
    "            pl.col(\"datetime\").cast(pl.Date).alias(\"date\"),\n",
    "        )\n",
    "\n",
    "        for add_features in [\n",
    "            self._add_general_features,\n",
    "            self._add_client_features,\n",
    "            self._add_forecast_weather_features,\n",
    "            self._add_historical_weather_features,\n",
    "            self._add_target_features,\n",
    "            self._add_holidays_features,\n",
    "            self._reduce_memory_usage,\n",
    "            self._drop_columns,\n",
    "        ]:\n",
    "            df_features = add_features(df_features)\n",
    "\n",
    "        df_features = self._to_pandas(df_features, y)\n",
    "\n",
    "        return df_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.name = \"ensembled_model\"\n",
    "        self.target_diff = \"target_48h\"\n",
    "        self.is_fitted = False\n",
    "        \n",
    "        #local\n",
    "        self.model_consumption_catboost = joblib.load(os.path.join( \"..\\Model\", \"model_consumption_catboost.pkl\"))\n",
    "        self.model_production_catboost = joblib.load(os.path.join( \"..\\Model\", \"model_production_catboost.pkl\"))\n",
    "        self.model_consumption_diff_catboost = joblib.load(os.path.join( \"..\\Model\", \"model_consumption_diff_catboost.pkl\"))\n",
    "        self.model_production_diff_catboost = joblib.load(os.path.join( \"..\\Model\", \"model_production_diff_catboost.pkl\"))\n",
    "\n",
    "        self.model_consumption_lightgbm = joblib.load(os.path.join( \"..\\Model\", \"model_consumption_lightgbm.pkl\"))\n",
    "        self.model_production_lightgbm = joblib.load(os.path.join( \"..\\Model\", \"model_production_lightgbm.pkl\"))\n",
    "        self.model_consumption_diff_lightgbm = joblib.load(os.path.join( \"..\\Model\", \"model_consumption_diff_lightgbm.pkl\"))\n",
    "        self.model_production_diff_lightgbm = joblib.load(os.path.join( \"..\\Model\", \"model_production_diff_lightgbm.pkl\"))\n",
    "        \n",
    "        \n",
    "        # #kaggle\n",
    "        # self.model_consumption_catboost = joblib.load(os.path.join( \"/kaggle/input/cat-lgb-model\", \"model_consumption_catboost.pkl\"))\n",
    "        # self.model_production_catboost = joblib.load(os.path.join( \"/kaggle/input/cat-lgb-model\", \"model_production_catboost.pkl\"))\n",
    "        # self.model_consumption_diff_catboost = joblib.load(os.path.join( \"/kaggle/input/cat-lgb-model\", \"model_consumption_diff_catboost.pkl\"))\n",
    "        # self.model_production_diff_catboost = joblib.load(os.path.join( \"/kaggle/input/cat-lgb-model\", \"model_production_diff_catboost.pkl\"))\n",
    "\n",
    "        # self.model_consumption_lightgbm = joblib.load(os.path.join( \"/kaggle/input/cat-lgb-model\", \"model_consumption_lightgbm.pkl\"))\n",
    "        # self.model_production_lightgbm = joblib.load(os.path.join( \"/kaggle/input/cat-lgb-model\", \"model_production_lightgbm.pkl\"))\n",
    "        # self.model_consumption_diff_lightgbm = joblib.load(os.path.join( \"/kaggle/input/cat-lgb-model\", \"model_consumption_diff_lightgbm.pkl\"))\n",
    "        # self.model_production_diff_lightgbm = joblib.load(os.path.join( \"/kaggle/input/cat-lgb-model\", \"model_production_diff_lightgbm.pkl\"))\n",
    "\n",
    "\n",
    "\n",
    "        self.model_consumption = VotingRegressor(estimators=[('catboost_consumption', self.model_consumption_catboost), \n",
    "                                                                      ('lightgbm_consumption', self.model_consumption_lightgbm)],\n",
    "                                                                      weights=[0.2, 0.8])\n",
    "        self.model_consumption_diff = VotingRegressor(estimators=[('catboost_consumption_diff', self.model_consumption_diff_catboost), \n",
    "                                                                           ('lightgbm_consumption_diff', self.model_consumption_diff_lightgbm)],\n",
    "                                                                           weights=[0.2, 0.8])\n",
    "        self.model_production = VotingRegressor(estimators=[('catboost_production', self.model_production_catboost), \n",
    "                                                                     ('lightgbm_production', self.model_production_lightgbm)],\n",
    "                                                                     weights=[0.2, 0.8])\n",
    "        self.model_production_diff = VotingRegressor(estimators=[('catboost_production_diff', self.model_production_diff_catboost),                                                                \n",
    "                                                                          ('lightgbm_production_diff', self.model_production_diff_lightgbm)],\n",
    "                                                                            weights=[0.2, 0.8])\n",
    "\n",
    "\n",
    "    def fit(self, df_train_features):\n",
    "        mask = df_train_features[\"is_consumption\"] == 1\n",
    "        self.model_consumption.fit(\n",
    "            X=df_train_features[mask].drop(columns=[\"target\"]),\n",
    "            y=df_train_features[mask][\"target\"],\n",
    "        )\n",
    "        self.model_consumption_diff.fit(\n",
    "            X=df_train_features[mask].drop(columns=[\"target\"]),\n",
    "            y=df_train_features[mask][\"target\"]\n",
    "            - df_train_features[mask][self.target_diff].fillna(0),\n",
    "        )\n",
    "\n",
    "        mask = df_train_features[\"is_consumption\"] == 0\n",
    "        self.model_production.fit(\n",
    "            X=df_train_features[mask].drop(columns=[\"target\"]),\n",
    "            y=df_train_features[mask][\"target\"],\n",
    "        )\n",
    "        self.model_production_diff.fit(\n",
    "            X=df_train_features[mask].drop(columns=[\"target\"]),\n",
    "            y=df_train_features[mask][\"target\"]\n",
    "            - df_train_features[mask][self.target_diff].fillna(0),\n",
    "        )\n",
    "\n",
    "        self.is_fitted = True\n",
    "\n",
    "    def save(self):\n",
    "        joblib.dump(self.model_consumption, os.path.join( \"..\\Model\", \"model_consumption_VotingRegressor.pkl\"))\n",
    "        joblib.dump(self.model_production, os.path.join( \"..\\Model\", \"model_production_VotingRegressor.pkl\"))\n",
    "        joblib.dump(self.model_consumption_diff, os.path.join( \"..\\Model\", \"model_consumption_diff_VotingRegressor.pkl\"))\n",
    "        joblib.dump(self.model_production_diff, os.path.join( \"..\\Model\", \"model_production_diff_VotingRegressor.pkl\")) \n",
    "\n",
    "        # #kaggle\n",
    "        # joblib.dump(self.model_consumption, os.path.join( \"/kaggle/working\", \"model_consumption_VotingRegressor.pkl\"))\n",
    "        # joblib.dump(self.model_production, os.path.join( \"/kaggle/working\", \"model_production_VotingRegressor.pkl\"))\n",
    "        # joblib.dump(self.model_consumption_diff, os.path.join( \"/kaggle/working\", \"model_consumption_diff_VotingRegressor.pkl\"))\n",
    "        # joblib.dump(self.model_production_diff, os.path.join( \"/kaggle/working\", \"model_production_diff_VotingRegressor.pkl\"))\n",
    "\n",
    "    def predict(self, df_features):\n",
    "        predictions = np.zeros(len(df_features))\n",
    "\n",
    "        mask = df_features[\"is_consumption\"] == 1\n",
    "        predictions[mask.values] = np.clip(\n",
    "            self.model_consumption.predict(df_features[mask]) * 0.5\n",
    "            + (\n",
    "                df_features[mask][self.target_diff].fillna(0).values\n",
    "                + self.model_consumption_diff.predict(df_features[mask])\n",
    "            )\n",
    "            * 0.5,\n",
    "            0,\n",
    "            np.inf,\n",
    "        )\n",
    "\n",
    "        mask = df_features[\"is_consumption\"] == 0\n",
    "        predictions[mask.values] = np.clip(\n",
    "            self.model_production.predict(df_features[mask]) * 0.5\n",
    "            + (\n",
    "                df_features[mask][self.target_diff].fillna(0).values\n",
    "                + self.model_production_diff.predict(df_features[mask])\n",
    "            )\n",
    "            * 0.5,\n",
    "            0,\n",
    "            np.inf,\n",
    "        )\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Validation:\n",
    "    def __init__(self, validation_start, validation_end, data_storage):\n",
    "        self.validation_start = validation_start\n",
    "        self.validation_end = validation_end\n",
    "        self.data_storage_global = data_storage\n",
    "        self.data_storage_train = self._generate_train_data_storage()\n",
    "        self.iter_test = self._generate_iter_test()\n",
    "\n",
    "    def _generate_train_data_storage(self):\n",
    "        data_storage = copy.deepcopy(self.data_storage_global)\n",
    "\n",
    "        data_storage.df_data = data_storage.df_data.filter(\n",
    "            pl.col(\"datetime\")\n",
    "            < self.validation_start\n",
    "            - datetime.timedelta(days=1)\n",
    "            - datetime.timedelta(hours=11)\n",
    "        )\n",
    "\n",
    "        data_storage.df_target = data_storage.df_target.filter(\n",
    "            pl.col(\"datetime\")\n",
    "            < self.validation_start\n",
    "            - datetime.timedelta(days=1)\n",
    "            - datetime.timedelta(hours=11)\n",
    "        )\n",
    "\n",
    "        data_storage.df_client = data_storage.df_client.filter(\n",
    "            pl.col(\"date\")\n",
    "            < self.validation_start\n",
    "            - datetime.timedelta(days=1)\n",
    "            - datetime.timedelta(hours=11 + 23)\n",
    "        )\n",
    "\n",
    "        data_storage.df_gas_prices = data_storage.df_gas_prices.filter(\n",
    "            pl.col(\"forecast_date\")\n",
    "            < self.validation_start\n",
    "            - datetime.timedelta(days=1)\n",
    "            - datetime.timedelta(hours=10)\n",
    "        )\n",
    "\n",
    "        data_storage.df_electricity_prices = data_storage.df_electricity_prices.filter(\n",
    "            pl.col(\"forecast_date\")\n",
    "            < self.validation_start\n",
    "            - datetime.timedelta(days=1)\n",
    "            + datetime.timedelta(hours=13)\n",
    "        )\n",
    "\n",
    "        data_storage.df_historical_weather = data_storage.df_historical_weather.filter(\n",
    "            pl.col(\"datetime\")\n",
    "            < self.validation_start\n",
    "            - datetime.timedelta(days=1)\n",
    "            - datetime.timedelta(hours=0)\n",
    "        )\n",
    "\n",
    "        return data_storage\n",
    "\n",
    "    def _generate_iter_test(self):\n",
    "        result = []\n",
    "        df_data = self.data_storage_global.df_data.to_pandas()\n",
    "        df_target = self.data_storage_global.df_target.to_pandas()\n",
    "        df_client = self.data_storage_global.df_client.to_pandas()\n",
    "        df_historical_weather = (\n",
    "            self.data_storage_global.df_historical_weather.to_pandas()\n",
    "        )\n",
    "        df_gas_prices = self.data_storage_global.df_gas_prices.to_pandas()\n",
    "        df_electricity_prices = (\n",
    "            self.data_storage_global.df_electricity_prices.to_pandas()\n",
    "        )\n",
    "        df_forecast_weather = self.data_storage_global.df_forecast_weather.to_pandas()\n",
    "\n",
    "        for current_time in pd.date_range(\n",
    "            self.validation_start, self.validation_end, freq=\"D\"\n",
    "        ):\n",
    "            df_test = df_data[\n",
    "                (df_data[\"datetime\"] >= current_time + datetime.timedelta(hours=13))\n",
    "                & (\n",
    "                    df_data[\"datetime\"]\n",
    "                    < current_time + datetime.timedelta(hours=13 + 24)\n",
    "                )\n",
    "            ]\n",
    "\n",
    "            df_sample_prediction = df_test.copy().rename(\n",
    "                columns={\"target\": \"real_target\"}\n",
    "            )\n",
    "            df_test.drop(columns=[\"target\"], inplace=True)\n",
    "\n",
    "            df_new_target = df_target[\n",
    "                (\n",
    "                    df_target[\"datetime\"]\n",
    "                    >= current_time - datetime.timedelta(hours=11 + 24)\n",
    "                )\n",
    "                & (df_target[\"datetime\"] < current_time - datetime.timedelta(hours=11))\n",
    "            ]\n",
    "\n",
    "            df_new_client = df_client[\n",
    "                (df_client[\"date\"] >= current_time - datetime.timedelta(hours=11 + 24))\n",
    "                & (df_client[\"date\"] < current_time - datetime.timedelta(hours=11 + 23))\n",
    "            ]\n",
    "\n",
    "            df_new_historical_weather = df_historical_weather[\n",
    "                (\n",
    "                    df_historical_weather[\"datetime\"]\n",
    "                    >= current_time - datetime.timedelta(hours=24)\n",
    "                )\n",
    "                & (\n",
    "                    df_historical_weather[\"datetime\"]\n",
    "                    < current_time - datetime.timedelta(hours=0)\n",
    "                )\n",
    "            ]\n",
    "\n",
    "            df_new_electricity_prices = df_electricity_prices[\n",
    "                (\n",
    "                    df_electricity_prices[\"forecast_date\"]\n",
    "                    >= current_time - datetime.timedelta(hours=11)\n",
    "                )\n",
    "                & (\n",
    "                    df_electricity_prices[\"forecast_date\"]\n",
    "                    < current_time + datetime.timedelta(hours=13)\n",
    "                )\n",
    "            ]\n",
    "\n",
    "            df_new_gas_prices = df_gas_prices[\n",
    "                (\n",
    "                    df_gas_prices[\"forecast_date\"]\n",
    "                    >= current_time - datetime.timedelta(hours=11)\n",
    "                )\n",
    "                & (\n",
    "                    df_gas_prices[\"forecast_date\"]\n",
    "                    < current_time - datetime.timedelta(hours=10)\n",
    "                )\n",
    "            ]\n",
    "\n",
    "            df_new_forecast_weather = df_forecast_weather[\n",
    "                (\n",
    "                    df_forecast_weather[\"origin_datetime\"]\n",
    "                    >= current_time - datetime.timedelta(hours=9)\n",
    "                )\n",
    "                & (\n",
    "                    df_forecast_weather[\"origin_datetime\"]\n",
    "                    < current_time - datetime.timedelta(hours=8)\n",
    "                )\n",
    "            ]\n",
    "\n",
    "            result.append(\n",
    "                (\n",
    "                    df_test,\n",
    "                    df_new_target,\n",
    "                    df_new_client,\n",
    "                    df_new_historical_weather,\n",
    "                    df_new_forecast_weather,\n",
    "                    df_new_electricity_prices,\n",
    "                    df_new_gas_prices,\n",
    "                    df_sample_prediction,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return result\n",
    "\n",
    "    def calculate_validation_score(self, features_generator_class, model):\n",
    "        data_storage = copy.deepcopy(self.data_storage_train)\n",
    "        features_generator = features_generator_class(data_storage)\n",
    "        df_train_features = features_generator.generate_features(\n",
    "            data_storage.df_target\n",
    "        )\n",
    "        df_train_features = df_train_features[df_train_features[\"target\"].notnull()]\n",
    "\n",
    "        model.fit(df_train_features) #medel training \n",
    "        model.save()#model saving\n",
    "\n",
    "        predictions = []\n",
    "        for (\n",
    "            df_test,\n",
    "            df_new_target,\n",
    "            df_new_client,\n",
    "            df_new_historical_weather,\n",
    "            df_new_forecast_weather,\n",
    "            df_new_electricity_prices,\n",
    "            df_new_gas_prices,\n",
    "            df_sample_prediction,\n",
    "        ) in tqdm(self.iter_test):\n",
    "            data_storage.update_with_new_data(\n",
    "                df_new_client=df_new_client,\n",
    "                df_new_gas_prices=df_new_gas_prices,\n",
    "                df_new_electricity_prices=df_new_electricity_prices,\n",
    "                df_new_forecast_weather=df_new_forecast_weather,\n",
    "                df_new_historical_weather=df_new_historical_weather,\n",
    "                df_new_target=df_new_target,\n",
    "            )\n",
    "\n",
    "            df_test = data_storage.preprocess_test(df_test)\n",
    "            df_test_features = features_generator.generate_features(df_test)\n",
    "            df_sample_prediction[\"target\"] = model.predict(df_test_features)\n",
    "\n",
    "            df_sample_prediction[\"score\"] = np.abs(\n",
    "                df_sample_prediction[\"target\"] - df_sample_prediction[\"real_target\"]\n",
    "            )\n",
    "            predictions.append(df_sample_prediction)\n",
    "\n",
    "        df_predictions = pd.concat(predictions)\n",
    "        assert (\n",
    "            df_predictions[df_predictions[\"real_target\"].notnull()][\"score\"]\n",
    "            .isnull()\n",
    "            .mean()\n",
    "            == 0\n",
    "        )\n",
    "        \n",
    "        data_predictions_each_county_mean_consumption =  df_predictions[df_predictions[\"is_consumption\"] == 1].groupby(\"county\").mean()        \n",
    "        plt.figure(figsize=(20, 10))\n",
    "        sns.barplot(x=data_predictions_each_county_mean_consumption.index, y=data_predictions_each_county_mean_consumption[\"score\"])\n",
    "        plt.title(\"Consumption_MAE_each_county\")\n",
    "        plt.show()\n",
    "\n",
    "        data_predictions_each_sagment_mean_production =  df_predictions[df_predictions[\"is_consumption\"] == 0].groupby(\"county\").mean()\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        sns.barplot(x=data_predictions_each_sagment_mean_production.index, y=data_predictions_each_sagment_mean_production[\"score\"])\n",
    "        plt.title(\"Production_MAE_each_county\")\n",
    "        plt.show()\n",
    "\n",
    "        data_predictions_each_datetime_mean_consumption =  df_predictions[df_predictions[\"is_consumption\"] == 1].groupby(\"datetime\").mean()\n",
    "        wide_df1 = pd.DataFrame(data_predictions_each_datetime_mean_consumption, \n",
    "                                data_predictions_each_datetime_mean_consumption.index, [\"target\", \"real_target\"])\n",
    "        \n",
    "        data_predictions_each_datetime_mean_production =  df_predictions[df_predictions[\"is_consumption\"] == 0].groupby(\"datetime\").mean()\n",
    "        wide_df0 = pd.DataFrame(data_predictions_each_datetime_mean_production, \n",
    "                                data_predictions_each_datetime_mean_production.index, [\"target\", \"real_target\"])\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        sns.lineplot(data=wide_df1)\n",
    "        plt.title(\"Mean_Consumption_all_prosumers\")\n",
    "        plt.show()\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        plt.title(\"Mean_Production_all_prosumers\")\n",
    "        sns.lineplot(data=wide_df0)\n",
    "        plt.show()\n",
    "       \n",
    "        if hasattr(model, \"name\"):\n",
    "            model_name = model.name\n",
    "        else:\n",
    "            model_name = model.__class__.__name__\n",
    "        \n",
    "        gc.collect()\n",
    "        return {\"model_name\": model_name, \"MAE\": df_predictions[\"score\"].mean()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_storage = DataStorage()\n",
    "validation = Validation(\n",
    "    validation_start=pd.to_datetime('2023-05-17 11:00:00'),\n",
    "    validation_end=pd.to_datetime('2023-05-30 11:00:00'),\n",
    "    data_storage=data_storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation.calculate_validation_score(\n",
    "    features_generator_class=FeaturesGenerator,\n",
    "    model=Model()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF2.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
